"""
In order for our mails to be used in any kind of algorithm, we 
first have to transform the non-numeric arrays of mails into numeric
representations of our mails.
"""

import os
import importlib.util
import pandas as pd
from gensim import corpora
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer


class WordRepresentation:

    def __init__(self, data=None, encoding=None):
        """
        Initiates an object of type WordRepresentation.

        Parameter
        ----------
        The paramater data can be a an object of class mails_data (from treatment.py) or None. 
        This constructor will load the data from the usual dataset directory
        and use treatement.py to apply a pretreatement to it if None is used.

        The paramater encoding is a string used as paramater for encoding options.
        (exemple: 'utf-8')
        """
        if data == None:
            cwd = os.path.abspath(os.getcwd())
            treatement_path = os.path.join("pretreatment", "treatment.py")
            spec = importlib.util.spec_from_file_location(
                "treatment", os.path.join(cwd, treatement_path))
            pretreatement = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(pretreatement)
            data = pretreatement.mails_data()

        self.pretreatement_obj = data
        self.data = data.vector_of_mails()
        self.encoding = encoding
        self.dictionary = None

        # For labelization
        self.label_names = ['Déménagement', 'Relève de compteur', 'Réclamation',
                             'Contrat – Coordonnées personnelles', 'Facture – Paiement', 'Espace client']
        self.labels =  self.pretreatement_obj.get_mails_label()
        self.unique_labels, self.unique_nammed_labels = None, None

    def count(self):
        """
        A basic count function that outputs a matrix, of size 
        (nb_of_documents x nb_of_words) that contains the number
        of occurences of word j in document i when the user
        calls count()[i,j].
        """

        vectorizer = CountVectorizer()
        return vectorizer.fit_transform(self.data).toarray()

    def tfidf(self, use_spicy=False, use_pandas=False, use_numpy=False):
        """
        Outputs a representation of the corpus where the output values correspond to
        an application of the TF-IDF forumla. 

        Paramaters
        ----------

        use_spicy: returns data of type <class 'scipy.sparse.csr.csr_matrix'>

        use_pandas: returns data of type <class 'pandas.core.frame.DataFrame'>
        This panda data frame also contains extra information about the feature
        names (ie. the name of the words)

        use_numpy: returns data of type <class 'numpy.ndarray'>

        """
        vectorizer = TfidfVectorizer(encoding=self.encoding)
        vectors = vectorizer.fit_transform(self.data)

        if use_pandas + use_numpy + use_spicy != 1:
            raise TypeError(
                "tfidf must have one and only one 'use' option set.")

        if use_spicy:
            return vectors

        if use_pandas:
            feature_names = vectorizer.get_feature_names()
            return pd.DataFrame(data=vectors.todense().tolist(), columns=feature_names)

        if use_numpy:
            return vectors.toarray()

    def init_dictionary(self):
        """
        This method initializes a dictionary of the corpus and returns it
        """

        self.dictionary = corpora.Dictionary(
            self.pretreatement_obj.bag_of_words_per_mail())
        return self.dictionary

    def numeric_bow(self):
        """
        This method outputs a bag of word representation of the corpus based
        on the dictionary generated by init_dictionary.
        This bag of words, is a list of pairs (key, number of occurences)

        The fact that init_dictionary is used, means that the number of occurences
        will always be one.

        The output is a list of lists: one list corresponding to one mail.

        If init_dictionary was never called. This method will do it.
        """

        if self.dictionary == None:
            self.init_dictionary()

        return [self.dictionary.doc2bow(text) for text in self.pretreatement_obj.bag_of_words_per_mail()]

    def dict_bow(self):
        """
        This method outputs a bag of word representation of the corpus based
        on the dictionary generated by init_dictionary.
        This bag of words, is of class 'dict' and contains the token names associated
        to their respective keys in the dictionary

        If init_dictionary was never called. This method will do it.
        """

        if self.dictionary == None:
            self.init_dictionary()

        self.dictionary[0]  # This is only to "load" the dictionary.
        return self.dictionary.id2token

    def init_unique_labels(self):
        """
        This method outputs an unidimentional vector of size (number of mails)
        containing the label each mail has.

        In case a mail has more than one label. This method only considers the
        first it founds.
        """

        if not self.unique_labels == None:
            return self.unique_labels

        self.unique_labels, self.unique_nammed_labels = [],[]
        label_exists = 1 # Making sure all mails are labeled

        for vect in self.labels:
            if label_exists == 0:
                raise Exception("Cannot deal with unlabeled mails.")
            for i,label in enumerate(vect):
                label_exists = 0
                if label:
                    self.unique_labels.append(i)
                    self.unique_nammed_labels.append(self.label_names[i])
                    label_exists = 1
                    break

        return self.unique_labels, self.unique_nammed_labels