{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "committed-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LDA_word_cloud import word_cloud\n",
    "import os\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import importlib.util\n",
    "spec = importlib.util.spec_from_file_location(\n",
    "    \"treatement\", os.path.abspath(os.path.abspath(os.path.join(os.getcwd(), os.pardir))) + \"/pretreatment/treatment.py\")\n",
    "pretreatement = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(pretreatement)\n",
    "data = pretreatement.mails_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "gross-heavy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "directory = \"./data/mails/\"\n",
    "\n",
    "# The mails\n",
    "mails = data.vector_of_mails()\n",
    "bow_per_mail = data.bag_of_words_per_mail()\n",
    "\n",
    "print(mails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "advance-intersection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 0\n",
      "Number of documents: 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5c4352557a49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Make a index to word dictionary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# This is only to \"load\" the dictionary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mid2word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid2token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pi_env/lib/python3.8/site-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, tokenid)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;31m# recompute id->word accordingly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid2token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrevdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken2id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid2token\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenid\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# will throw for non-existent ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# The dictionary\n",
    "dictionary = corpora.Dictionary(bow_per_mail)\n",
    "\n",
    "# The corpus\n",
    "corpus = [dictionary.doc2bow(text) for text in bow_per_mail]\n",
    "\n",
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))\n",
    "\n",
    "# Build LDA model\n",
    "# Set training parameters.\n",
    "num_topics = 4\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")\n",
    "\n",
    "# Print the Keyword in the last topic\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]\n",
    "\n",
    "# Compute Coherence Score\n",
    "top_topics = lda_model.top_topics(corpus)  # , num_words=20)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "pprint(top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-layout",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
